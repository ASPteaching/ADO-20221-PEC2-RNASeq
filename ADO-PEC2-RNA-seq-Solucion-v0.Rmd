---
title: "Analisis de Datos Omicos. Segunda PEC"
author: "Alex Sanchez"
date: "Enero 2022"
output:
   html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    theme: darkly
    highlight: textmate
    number_sections: true
editor_options: 
  chunk_output_type: console
---


```{r class.source = 'fold-hide', setup, include=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=FALSE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```


# Introducción

## Solución de la PEC-2

_El enunciado de la PEC establece unas directrices para la solución. por ejemplo que el código esté en un anexo para facilitar la legibilidad o que se incluya una sección de materiales y métodos._

_La solución que os proporcionamos está pensada para ayudar a entender el proceso y los detalles de los análisis,  lo que se podría o debería haber hecho, por lo que ésta estructura de OBJETIVOS -> METODOS -> RESULTADOS -> DISCUSION -> Apéndices, puede no ser tan obvia._

_En todo caso, es una propuesta de solución que podéis utilizar para contrastar con la vuestra y, eventualmente, para entender mejor el porqué de cada paso._

La solución se encuentra disponible, y actualizada (constantemente) en [https://github.com/ASPteaching/ADO20221-PEC2-RNASeq.git](https://github.com/ASPteaching/ADO20221-PEC2-RNASeq.git)

## Resumen

Este ejercicio realiza un análisis de expresión diferencial, basado en datos de RNA-Seq, para encontrar diferencias en la respuesta inmune entre enfermos graves y severos de COVID-19. Se basa en unos datos de contajes descargados del repositorio Gene Expresión Omnibus y se lleva a cabo con un total de 20 muestras, 10 por grupo, extraídas aleatoriamente de dos grupos (SANO y COVID) cada uno de 17 muestras. El análisis se llevó a cabo utilizando un pipeline estándar de análisis de RNA-seq, como el descrito en "https://github.com/ASPteaching/Analisis_de_datos_omicos-Ejemplo_2-RNASeq". Como resultado del proceso se detectaron XXX transcritos diferencialmente expresados. Un análisis de significación biológica reveló que funciones como YYY aparecen enriquecidas.

## Objetivos

Este ejercicio tiene un doble objetivo
- Implementar y ejecutar un pipeline básico de análisis de datos de RNA-seq, adaptándolo de otros pre-existentes.
- Aplicar dicho pipe-line al análisis de unos datos públicos que se proporcionan con este fin.
- Un tercer objetivo, que puede considerarse implícito en lo anterior es comunicar el proceso y los resultado siguiendo los estándares habituales de ciencia de datos (R/Rmarkdown).

## Infraestructura informática para el análisis

Este estudio se llevará a cabo usando R/Bioconductor por lo que es preciso tener instaladas un conjunto de librerías. Esto puede hacerse siguiendo el procedimiento descrito a continuación.

**El código que se presenta debería ejecutarse tan sólo una vez!**

```{r instalaPaquetes, librerias, echo=TRUE, eval=FALSE}
if(!require(BiocManager)){
      install.packages("BiocManager", dep=TRUE)
}

installifnot <- function (pckgName, BioC=TRUE){
  if(BioC){
    if(!require(pckgName, character.only=TRUE)){
      BiocManager::install(pckgName)
    }
  }else{
    if(!require(pckgName, character.only=TRUE)){
      install.packages(pckgName, dep=TRUE)
    }
  }
}
installifnot("limma")
installifnot("edgeR")
# installifnot("DESeq2")
installifnot("org.Hs.eg.db")
installifnot("clusterProfiler")
installifnot("dplyr", BioC=FALSE)
installifnot("gplots", BioC=FALSE)
installifnot("ggvenn", BioC=FALSE)
installifnot("pheatmap")
installifnot("stringi", BioC=FALSE)
installifnot("prettydoc", BioC=FALSE)
installifnot("ggnewscale", BioC=FALSE)
```

Puede resultar útil, aunque no es para nada imprescindible, disponer de, al menos dos, directorios específicos:
- `datos` (o un nombre similar) donde guardar y de donde cargar  los datos.
- ` results`o (o un nombre similar) donde escribir los resultados.

Estos directorios pueden crearse antes del inicio de la ejecución del pipeline o comprobar su existencia en cada ejecución, creándolos en caso de que estén ausentes.

```{r directorios}
if(!dir.exists("datos")) dir.create("datos")
if(!dir.exists("results")) dir.create("results") 
```

# Los datos para el análisis

## Obtención de los datos y selección de las muestras

Los datos proporcionados no son los obtenidos directamente del proceso de secuenciación, imágenes o archivos FastQ, sino el resultado de pre-procesar éstos, es decir _un tabla de  contajes_, almacenada en el archivo `Rawcounts.csv`, que contiene el número de "reads" para cada muestra en cada tránscrito (60683 filas y 34 columnas). 


### Lectura de la matriz de contajes

Los datos del archivo `Rawcounts.csv` deben leerse. Normalmente el proceso de lectura crea un objeto  `data.frame`o un `tibble`, si se usa `tidyverse`, pero es práctico convertir dicho objeto en una _matriz_ que es el formato utilizado por la mayoría de paquetes de análisis.

```{r}
counts <- read.csv("datos/RawCounts.csv", row.names = 1)
countsMatrix <- as.matrix(counts)
rm(counts)
```

Con la información sobre los grupos u otras covariables o variables auxiliares se creará un objeto (el habitual "targets") que debe estar _sincronizado_ con el anterior. 

```{r creaTargets}
muestras<- colnames(countsMatrix)
grupos <- c(rep("COVID", 17), rep("SANO", 17))
colores=c(rep("red", 17), rep("blue", 17))
targets <- data.frame(sample=muestras, 
                      group=grupos, cols=colores)
rownames(targets) <- targets[,1]
```

Los nombres de fila del objeto "targets" deben coincidir-o al menos identificarse- con los nombres de columna de la matriz de contajes.

```{r sincronizacion}
if (sum(colnames(countsMatrix)!=rownames(targets))>0)
  cat("Verifique que las filas del objeto targets coinciden con las columnas de la matriz de datos")
```

# Preprocesado de los datos

## Selección aleatoria de muestras

Para obtener una muestra aleatoria que tenga 10 individuos por grupo debemos sortear las columnas de cada tipo ("COVID" y "SANO") por separado. Con esta muestra crearemos un subconjunto de la matriz de expresión que tendrá los mismos genes y tan sólo 20 columnas. 

La selección aleatoria la basaremos en la columna `group` del objeto `targets`.

_Una posible forma de realizar este sorteo_ consiste en crear una función que extraiga un cierto número de filas de un tipo de grupo.

```{r getRowsFromGroup}
getRowsFromGroup <- function(unGrupo, numRows){
  G <-which(targets$group==unGrupo)
  s <- sample(G, numRows)
}
```

Con esta función se extraen 10 muestras al azar, de entre las 17 de cada grupo.

```{r randomSampling}
set.seed(12345678)
S1 <- getRowsFromGroup("COVID", 10)
S2 <- getRowsFromGroup("SANO", 10)
selectedSamples <- c(S1,S2)
# show(selectedSamples)
```
El sorteo indica que se seleccionen las columnas ```{r selectedSamples} de la matriz de datos y las mismas filas del objeto targets.

Una vez realizada la extracción aleatoria se actualizaran tanto los contajes como el objeto "targets", de forma que la sincronización entre filas y columnas continua siendo válida.

```{r subconjuntObjetos}
selectedCounts <- countsMatrix[,selectedSamples]
selectedTargets <-targets [selectedSamples,] 
dim(selectedCounts)
dim(selectedTargets)
sum(colnames(selectedCounts)!=rownames(selectedTargets))
```


## Estandarización de los contajes 

Además de filtrar, es bueno expresar los contajes en "CPMs" es decir "counts per million", lo que no modificará los resultados del filtraje, pero estandarizará los valores, lo que es útil y necesario para los análisis posteriores.

Para la estandarización se utilizará la función `cpm()` del paquete `edgeR`. 

Como puede observarse la función `cpm` tan sólo afecta los contajes mayores

```{r getCPM}
library(edgeR)
selectedCounts[1:5,1:6]
counts.CPM <- cpm(selectedCounts)
counts.CPM[1:5,1:6]
```

Una vez los datos estan como CPMs, se procede a filtrarlos, 

## Filtraje de genes poco expresados

Los genes con recuentos muy bajos en todas las librerías proporcionan poca evidencia de expresión diferencial por lo que es habitual eliminar aquellos genes que, o bien son poco variables, o bien presentan poca o nula expresión en la mayoría de las muestras.

En este caso, siguiendo las indicaciones proporcionadas, se opta por _conservar únicamente aquellos genes que presentan algún valor en, al menos, tres muestras **de cada grupo**_.

```{r subsetThreshold}
thresh <- counts.CPM > 0
keep <- (rowSums(thresh[,1:10]) >= 3) &
        (rowSums(thresh[,11:20]) >= 3)
counts.keep <- counts.CPM[keep,]
dim(counts.CPM)
dim(counts.keep)
```

Aunque no sea más que un ejemplo basta con ver los dos primeros genes para comprobar como el primero no cumple la condición, en el grupo "SANO", mientras que los siguientes sí que la cumplen. Por lo tanto, al filtrar desaparece el primer gen de la matriz filtrada, pero no los dos siguientes.

```{r comparaMatrices}
head(counts.CPM)
head(counts.keep)
```

## Uso de clases específicas para manejar los datos

Cuando se trabaja con distintos objetos referidos a unos mismos datos, como la matriz de contajes y el objeto "targets",  es útil disponer de clases contenedoras que permitan trabajar con todos ellos a la vez, lo que no sólo facilita el trabajo sino que ayuda a evitar "desincronizaciones". 

Éste es el caso de la clase `ExpressionSet` habitualmente utilizada con microarrays o de la clase que la generaliza, llamada  `SummarizedExperiment`. 

Para datos de contaje es habitual usar una clase similar a `ExpressionSet` llamada `DGEList`" pensadas para manejar datos de contajes , definida en el paquete `edgeR`. Esta clase, más simple que las anteriores, utiliza listas para almacenar recuentos de "reads" e información asociada de tecnologías de secuenciación o expresión génica digital. Puede encontrarse información al respecto en la ayuda del paquete `edgeR`.

```{r makeDGEObj0}
dgeObj <- DGEList(counts = counts.keep, 
                  lib.size = colSums(counts.keep),
                  norm.factors = rep(1,ncol(counts.keep)), 
                  samples = selectedTargets,
                  group = selectedTargets$group, 
                  genes = rownames(counts.keep), 
                  remove.zeros = FALSE)
dgeObj
```

Uno de los aspectos interesantes de estas clases es la posibilidad de extraer partes de todos los objetos a la vez con el operador de "subsetting". 

```{r makeDGEObj}
dim(dgeObj)
dgeObjShort<-dgeObj[,c(1:5, 11:15)]
# Library size information is stored in the samples slot
dgeObjShort$samples
colnames(dgeObjShort$counts)
```

Aunque podríamos haber creado el objeto a partir de todas las muestras, y haber realizado la extracción de genes y muestras posteriormente, hemos optado por no hacerlo para facilitar el seguimiento del proceso.

## Normalización

Además d estandarizar los contajes, es importante eliminar otros los sesgos de composición entre librerías. Esto puede hacerse aplicando la normalización por el método TMM que genera un conjunto de factores de normalización, donde el producto de estos factores y los tamaños de librería definen el tamaño efectivo de la biblioteca. 

La función `calcNormFactors`, de la librería `edgeR`, calcula los factores de normalización entre librerías.

```{r calcNormFactors}
library(edgeR)
dgeObj_norm <- calcNormFactors(dgeObj)
```

Esto no modificará la matriz de contajes, pero actualizará los factores de normalización en el objeto DGEList  (sus valores predeterminados son 1).

```{r}
dgeObj$counts[1:3, 1:5]
dgeObj_norm$counts[1:3, 1:5]
dgeObj$samples$norm.factors
dgeObj_norm$samples$norm.factors
```

Es decir, _aunque no se observen cambios en la matriz de contajes_, cuando se utilizan estos factores de normalización en algún cálculo la importancia de las distintas columnas se tendrá en cuenta.


**Resumiendo**

Los análisis que se realicen a continuación se basaran en la matriz de contajes, filtrada, estandarizada y normalizada, sobre la que además se toman logaritmo base dos.

```{r log2count_norm}
log2count_norm <- cpm(dgeObj_norm, log=TRUE)
```

Esta será nuestra matriz de partida para los análisis siguientes,


# Exploración de los datos

Una vez descartados los genes poco expresados y con los recuentos almacenados en un objeto `DGEList`,  podemos`proceder a realizar algunos gráficos exploratorios para determinar si los datos aparentan buena calidad y/o si presentan algun problema.

## Distribución de los contajes

Un diagrama de cajas con los datos, normalizados o no, muestra que la distribución de los contajes es muy asimétrica, lo que justifica la decisión de trabajar con los logaritmos de los datos.

La transformación logarítmica puede hacerse directamente pero es mejor usar la función `cpm`, como se ha hecho, que agrega una pequeña cantidad para evitar tomar logaritmos de cero.

```{r distriCounts1}
par(mfrow=c(2,1))
rawCounts <- dgeObj_norm$counts
boxplot(rawCounts, ylab="CPM",las=2, xlab="", col = dgeObj$samples$cols, cex.axis=0.7, main="Distribución de contajes")
boxplot(log2count_norm, ylab="Log2-CPM",las=2, xlab="", col=dgeObj$samples$cols, cex.axis=0.7, main="Distribución de log(contajes)")
abline(h=median(log2count_norm), col="blue")
par(mfrow=c(1,1))
```

## Análisis de similaridad entre las muestras

En general, en un estudio experimental en donde buscamos comparar distintas condiciones o tratamientos, esperaremos que las muestras pertencientes al mismo grupo _se parezcan_ más entre ellas que a las de los otros grupos.

Esta idea intuitiva puede concretarse a través de calcular y visualizar de alguna forma la similaridad entre las muestras. 

Esto puede hacerse de distintas formas, pero algunas de las más habituales son, el _cluster_ o agrupamiento jerárquico y los métodos de reducción de la dimensión como el análisis de componentes principales (PCA) o el escalamiento multidimensional (MDS). Éste último tiene la ventaja que permite visualizar en dimensión reducida las similaridades entre muestras, más que los datos directos que es lo que hace el PCA.

### Distancia entre muestras

La función `dist` permite calcular una _matriz de distancias_ que contiene las comparaciones dos a dos entre todas las muestras. Por defecto se utiliza una distancia euclídea.

```{r}
sampleDists <- dist(t(log2count_norm))
round(sampleDists,1)
```

Las matrices de distancias se pueden visualizar directamente con un heatmap.

```{r}
library(factoextra)
fviz_dist(sampleDists)
```

Como puede verse _las muestras tienden a agruparse por el factor SANO/COVID, aunque una de las muestras. COV155 se separa del resto de las del grupo COVID.

### Agrupamiento jerárquico

Un agrupamiento jerárquico proporciona una representación alternativa, también basada en la matriz de distancias.

```{r}
hc <-hclust(sampleDists)
plot(hc,labels = colnames(log2count_norm),main = "Agrpamiento jerárquico de las muestras", cex=0.8)
```

El dendrograma muestra la misma agrupación, sanos por un lado y COVID por otro, y el mismo comportamiento diferenciado de esta muestra COV155.

Una forma adicional de comprobar que, efectivamente, la mustra "COV155" difiere de las demas es verificar que el factor de normalización de dicha muestra es distinto al de los demás, lo que es coherente con el resto de visualizaciones y sugiere que es preciso _un mayor esfuerzo_ para hacerla similar al resto.

```{r}
normFactors <- dgeObj_norm$samples$norm.factors
names(normFactors)<- sampleNames <- rownames(dgeObj_norm$samples)
plot(normFactors, main= "Factores de normalización")
text(normFactors, sampleNames, pos=2, cex=0.7)
```
 
### Visualización en dimensión reducida

Un enfoque complementario para determinar las principales fuentes de variabilidad en los datos es la visualización en dimensión reducida, ya sea de los datos o de la matriz de similaridades.

Para la primera representación es habitual basarse en el resultado de un análisis de componentes principales (PCA) que representan las direcciones a lo largo de las cuales la variación en la matriz de datos es máxima, con la ventaja de que dichas direcciones son ortogonales (es decir independientes) y que explica cada una más información que la siguiente, por lo que con unas pocas dimensiones se suele poder explicar un alto porcentaje de la variabilidad.

De forma análoga, el escalamiento multidimensional permite llevar a cabo una transformación similar a la del PCA, pero con la matriz de distancias, lo que proporciona una representación en dimensión reducida que describe con relativa fidelidad las diferencias y similaridades entre muestras. 

Para esta segunda representación utilizaremos la función `plotMDS`.
Es un poco difícil ver exactamente qué está pasando con la gráfica predeterminada, aunque vemos muestras que se agrupan en pares. Para hacer esta gráfica más informativa, podemos colorear las muestras de acuerdo con la información de agrupación (por ejemplo. Estado):

```{r}
#sampleinfo$Status <- factor (sampleinfo$group)
col.status <- dgeObj_norm$samples$cols
plotMDS(log2count_norm,col=col.status, main="Status", cex=0.7)
```
Como puede verse, el gráfico muestra la misma agrupación "natural" que las visualizaciones anterioreslo que sugiere  que los grupos que se comparan parecen estar bien definidos.

## Detección de efecto batch

La detección de efecto batch puede hacerse, bien mediante la visualización de las muestras o mediante análisis de las covariables. Puesto que no se disponen de covariables sólo resta observar las visualizaciones para determinar si éstas sugieren alguna agrupación "no natural", es decir no ligada a la variable "estado de salud". 

Puesto que éste no es el caso, es decir, los datos se agrupan por SANOS/COVID, concluímos que _no parece_ existir ninguna fuente de variación superpuesta, que pudiera atribuirse a un posible efecto batch.


# Análisis de expresión diferencial

El objetivo del análisis de expresión diferencial es seleccionar genes cuya expresión difiere entre grupos. 

Al tratarse de contajes, que no son variables contínuas, la comparación puede llevarse a cabo usando modelos lineales generalizados o extensiones de éstos, creadas específicamente para datos de secuenciación.

Este es el caso específicamente de `edgeR` o `DESEQ2`. 

Una alternativa a estos paquetes es usar el  paquete `limma`, que ofrece la función `voom`,  que transforma los recuentos de "reads" en `logCMM`, teniendo en cuenta la relación media-varianza en los datos (Charity W. Law et al. 2014) y permite analizarlos mediante la aproximación habitual basada en modelos lineales.

## Selección de genes usando limma-Voom

La ventaja principal de esta aproximación es que permite trabajar con toda la flexibilidad de los modelos lineales para representar diseños experimentales, y, en muchos casos , aprovechar la experiencia previa del usuario en el manejo de limma.

### Matriz de diseño y de contrastes

Utilizando la variable `group` podemos definir una _matriz de diseño_ y, sobre ésta, los _contrastes_ que nos interesan.

```{r matrizDisenyo}
group = as.factor(dgeObj_norm$samples$group)
design = model.matrix(~ 0 + group)
colnames(design) = gsub("group", "", colnames(design))
row.names(design) = sampleNames
design
```

Dado que estamos interesados en las diferencias entre los grupos, necesitamos especificar qué comparaciones queremos llevar a cabo. Las comparaciones de interés se puede especificar utilizando la función `makeContrasts`. La matriz de contraste indica  qué columnas de la matriz `design` vamos a comparar. En este caso tan sólo se llevará a cabo una comparación.

```{r matrizContrastes}
cont.matrix = makeContrasts(CONTROLvsCOVID = COVID - SANO,
levels=colnames(design))
cont.matrix
```

### Transformación de los contajes

Tal como se ha indicado, no es posible aplicar un modelo lineal normal con datos de contajes. la transformación `voom` creará un nuevo objeto con campos equivalentes a los del DGELIST, en la que los contajes se han transdormado de forma que puedan ser analizados usando modelos lineales. O, mejor dicho, de forma que las inferencias realizadas, usando un modelo lineal normal resulten válidas.

```{r voom}
voomObj <- voom(dgeObj_norm, design)
voomObj
```

### Selección de genes diferencialmente expresados

Como en el caso de los microarrays el objeto `voomObj` y las matrices de diseño y contrastes se utilizaran para ajustar un modelo y, a continuación realizar las comparaciones especificadas sobre el modelo ajustado. El proceso finaliza con la regularización del estimador del error usando la función ` eBayes`.

```{r ajusteLM}
fit <- lmFit(voomObj)
fit.cont <- contrasts.fit(fit, cont.matrix)
fit.cont <- eBayes(fit.cont)
```

### Top tables

Los resultados de un análisis de expresión diferencial se pueden extraer con la  función `topTable`. Esta función genera una tabla de resultados cuyas columnas contienen información acerca de los genes y la diferencia entre los grupos comparados. Concretamente:

```{r topTable}
toptab <- topTable(fit.cont,coef=1,sort.by="p", number=nrow(fit.cont))
head(toptab)
```
### Visualización de los resultados

Para visualizar los resultados podemos usar un `volcanoPlot`:

```{r volcano}
volcanoplot(fit.cont,coef=1,highlight=100, main="COVID vs SANO")
```

Con el fin de observar si existen perfiles de expresión diferenciados podemo realizar un mapa de colores con los genes más diferencialmente expresados.

Es decir, fijamos un criterio de selección de genes y retenemos aquellos componentes de la tabla de resultados que lo cumplen. Por ejemplo: Genes con un p-balor ajustado inferior a 0.001 y un `fold-change' superior a 2.

```{r deg1VOOM}
topGenesBas <- rownames(subset(toptab, (abs(logFC)> 2) & (adj.P.Val < 0.01)))
length(topGenesBas)
```

Con la matriz de expresión de los genes que verifican dicha condición se puede construir un heatmap.

```{r mapaDeColores}
library(pheatmap)
mat  <- log2count_norm[topGenesBas, ]
mat  <- mat - rowMeans(mat)
pheatmap(mat)
```

Los dos grupos estan diferenciados, sobre todo en un subconjunto de genes en donde las expresiones toman signos (colores) distintos. En otro de los grupos parece que, en el grupo de individuops sanos los genes diferencialmente expresados se encuentran sobre-expresados en el grupo COVID, y apenas expresados en el grupo sanos.


## Análisis de expresión diferencial usando el paquete `edgeR`

El análisis con `edgeR` es similar al anterior (se originan en el mismo equipo de investigación) pero la modelización es distinta.

El análisis utiliza un GLM pero, en una forma que recuerda a lo que se hace con `limma`, realiza un paso adicional,en el que se calcula una estimación mejorada de la dispersión (variabilidad) de las muestras que integra las estimaciones individuales y la global mediante estimación Bayes empírica.


```{r}
y = estimateDisp(dgeObj_norm, design, robust=TRUE)
plotBCV(y)
```

Con este objeto, que añade a los contajes normalizados los estimadores mejorados de dispersión, se ajusta un modelo lineal generalizado con distribución binomial para los errores.

```{r}
fit <- glmQLFit(y, design, robust = TRUE)
```

Una vez ajustado el modelo se procede a construir el contraste y realizar el test.

De hecho podemos usar la matriz de contrastes que construímos para limma voom, en la misma forma que hemos reutilizado la de diseño.

```{r}
res <- glmQLFTest(fit, contrast = cont.matrix)
head(res)
```

Los resultados se almacenan en un objeto similar a la ' topTable' de `limma`.

```{r}
topTags_edge <- topTags(res, n=dim(log2count_norm)[1]) # todos los genes
head(topTags_edge)
```
 Podemos seleccionar los genes más diferencialmente expresados de la misma forma que hicimos con limma-voom
 
```{r}
topGenes_edge <- rownames(subset(topTags_edge$table, (abs(logFC)> 2) & (FDR < 0.01)))
length(topGenes_edge)
```
 
Obsérvese que la lista de genes seleccionados es muy similar en ambos casos.

```{r comparaVoomEdgeR}
library(ggvenn)
x = list(LimmaVoom = topGenesBas, edgeR = topGenes_edge)
ggvenn(x, fill_color = c("#0073C2FF", "#EFC000FF"), stroke_size = 0.5, set_name_size = 3)
```

El ejercicio pedía únicamente comparar los resultados de la selección con limmaVoom con otro método alternativo por lo que, por simplicidad omitiremos el análisis con DESEQ2 que puede verse aplicado en el ejemplo disponible en el ejemplo siguiente: [https://github.com/ASPteaching/Omics_data_analysis-Case_study_2-RNA-seq](https://github.com/ASPteaching/Omics_data_analysis-Case_study_2-RNA-seq).

# Anotación de resultados y análisis de significación biológica

Para el análisis de significación se utilizan dos listas de transcritos:

- La lista de transcritos diferencialmenete expresados
- La lista de tosos los tránscritos o "Universo"

Una alternativa obvia para definir la lista de transcritos diferencialmente expresados sería tomar los genes que han sido seleccionados por ambos métodos, es decir por `edgeR` y `limma-Voom`, que es una selección restrictiva pero fiable.

Como este tipo de análisis es muy exploratorio se utilizará una opción menos restrictiva, la unión de abas listas, es decir, los genes que han sido seleccionados por uno u otro de los métodos.  


```{r}
topGenes <- union(topGenesBas, topGenes_edge)
length(topGenes)
universe <- rownames(toptab)
length(universe)
```

## Anotación de los identificadores

Un detalle importante en los estudios de RNA-seq es que las unidades de expresión suelen ser _tránscritos_ no genes. En la práctica, esto determina que la mayoría de programas de análisis de enriquecimiento pueden perder detalle, porque para su uso se requiere tener los identificadores en formato "gen", habitualmente ENTREZ o SYMBOL.

Esto es posible, y de hecho sencillo de llevar a cabo, usando el paquete `annotate`.


```{r anotaTop}
library(org.Hs.eg.db)
AnnotationDbi::keytypes(org.Hs.eg.db)
topAnots = AnnotationDbi::select(org.Hs.eg.db, topGenes, c("SYMBOL", "ENTREZID", "GENENAME"),
keytype = "ENSEMBL")
head(topAnots)
dim(topAnots)
```

Como puede verse, el número de anotaciones es el mismo que el de identificadores ENSEMBL, lo que podría llevar a pensar que, es posible que, antes de subir los datos a GEO se hayan agrupado los contajes por genes.

Para la anotación del universo se procederá igual.

```{r}
univAnots = AnnotationDbi::select(org.Hs.eg.db, universe, c("SYMBOL", "ENTREZID", "GENENAME"), keytype = "ENSEMBL")
head(univAnots)
dim(univAnots)
```

En este caso se observa como hay más anotaciones que transcritos, lo que sugiere que múltiples tránscritos han sido mapeados en el mismo gen.

## Análisis de enriquecimiento

El paquete `clusterProfiler` admite identificadores de tipo ENSEMBL y permite gran variedad de análisis complementarios al enriquecimiento por lo que, es una de las mejores opcionespara el análisis de significación biológica.

En primer lugar se lleva a cabo un _Análisis de enriquecimiento_ con categorias de la ontología "Biological Process" que permite seleccionar aquellas categorías más enriquecidas en la lista de genes diferencialmente expresados.

```{r enrichment}
library(clusterProfiler)
library(org.Hs.eg.db)
ego = enrichGO(gene = topGenes, 
               universe=universe,
               keyType = "ENSEMBL", 
               OrgDb = org.Hs.eg.db,
               ont="BP",
               pAdjustMethod = "BH",
               pvalueCutoff = 0.05,
               qvalueCutoff = 0.05,
               readable = TRUE)
```

El objeto resultante del análisis contiene información sobre las categorías enriquecidas, el grado de enriquecimiento, o los genes anotados en las mismas. Este objeto puede salvarse a disco para su posterior consulta.

```{r saveEnrichedTerms}
head(ego[,-c(2,8)], n=5)
head(ego[,2:3], n=5)
head(ego[,c(2,8)], n=5)
write.table(ego, file="results/EnrichmentResults.csv", dec=".", sep=";")
```

Con los resultados del análisis de enriquecimiento se pueden llevar a cabo distintas visualizaciones cuya interpretación exacta puede verse en el manual de clusterProfiler.

Un dotplot muestra algunas categorias usando un código de tamaño para el número de genes en la categoría y de color para la significación.

```{r viewEnrichment1}
dotplot(ego, showCategory=7)
```


Un `cnetplot`muestra la relación entre genes y categorías enriquecidas.

```{r viewEnrichment2}
library(ggplot2)
ego2 = simplify(ego)
cnetplot(ego2, showCategory = 3, cex_category =0.3, 
         cex_label_category =0.7, cex_gene=0.2, cex_label_gene=0.4,
         circular=TRUE, colorEdge=TRUE)
```

Un `goplot` muestra, en forma de subgrafo de la Gene Ontology, las categorías que se relacionan, como ascendientes, con las categorías enriquecidas. Sirve para ver éstas, en contexto.

```{r viewEnrichment3}
library(enrichplot)
goplot(ego2, showCategory=10, cex=0.1)
```

Un heatplot`permite relacionar, de forma similar al cnetplot, las categorías y los genes anotados en ellas. Conceptualmente es interesante, pero la visibilidad es difícil.

```{r viewEnrichment5}
heatplot(ego2)
```

Finalmente, dada la abundancia de componentes que aparecen en los análisis, podemos mirar de agruparlos por su similaridad (cercanía dentro del grafo) y así obtener una visualización más compacta.

```{r viewEnrichment6}
term_similarity_matrix = pairwise_termsim(ego)
emapplot(term_similarity_matrix, showCategory = 15,
         group_category=TRUE, group_legend=TRUE)
```

Todos los gráficos se pueden, adicionalmente, enviar a una rchivo pdf para su posterior visualización.

```{r}
pdf(file="results/enrichmentPlots.pdf")
dotplot(ego, showCategory=7)
cnetplot(ego2, showCategory = 3, cex_category =0.3, 
         cex_label_category =0.7, cex_gene=0.2, cex_label_gene=0.4,
         circular=TRUE, colorEdge=TRUE)
goplot(ego2, showCategory=10, cex=0.1)
heatplot(ego2)
emapplot(term_similarity_matrix, showCategory = 15,
         group_category=TRUE, group_legend=TRUE)
dev.off()
```

# Discusión

# Apendice: Codigo del Análisis

Para extraer el código de este documento podemos usar la instrucción `knitr::purl("ADO-PEC2-RNA-seq-Solucion-v0.Rmd")` con el nombre del archivo.

Si insertamos el archivo resultante en un "chunk de código" marcado con `eval=FALSE` podremos ver todo el código con el formato adecuado.

```{r insertaCodigo,  echo=TRUE, eval=FALSE, highlight=TRUE}
## ----class.source = 'fold-hide', setup, include=FALSE---------------------
# library(knitr)
# library(rmdformats)
# 
# ## Global options
# options(max.print="75")
# opts_chunk$set(echo=FALSE,
# 	             cache=TRUE,
#                prompt=FALSE,
#                tidy=TRUE,
#                comment=NA,
#                message=FALSE,
#                warning=FALSE)
# opts_knit$set(width=75)


## ----instalaPaquetes, librerias, echo=TRUE, eval=FALSE--------------------
if(!require(BiocManager)){
      install.packages("BiocManager", dep=TRUE)
}

installifnot <- function (pckgName, BioC=TRUE){
  if(BioC){
    if(!require(pckgName, character.only=TRUE)){
      BiocManager::install(pckgName)
    }
  }else{
    if(!require(pckgName, character.only=TRUE)){
      install.packages(pckgName, dep=TRUE)
    }
  }
}
installifnot("limma")
installifnot("edgeR")
# installifnot("DESeq2")
installifnot("org.Hs.eg.db")
installifnot("clusterProfiler")
installifnot("dplyr", BioC=FALSE)
installifnot("gplots", BioC=FALSE)
installifnot("ggvenn", BioC=FALSE)
installifnot("pheatmap")
installifnot("stringi", BioC=FALSE)
installifnot("prettydoc", BioC=FALSE)
installifnot("ggnewscale", BioC=FALSE)


## ----directorios----------------------------------------------------------
if(!dir.exists("datos")) dir.create("datos")
if(!dir.exists("results")) dir.create("results") 


## -------------------------------------------------------------------------
counts <- read.csv("datos/RawCounts.csv", row.names = 1)
countsMatrix <- as.matrix(counts)
rm(counts)


## ----creaTargets----------------------------------------------------------
muestras<- colnames(countsMatrix)
grupos <- c(rep("COVID", 17), rep("SANO", 17))
colores=c(rep("red", 17), rep("blue", 17))
targets <- data.frame(sample=muestras, 
                      group=grupos, cols=colores)
rownames(targets) <- targets[,1]


## ----sincronizacion-------------------------------------------------------
if (sum(colnames(countsMatrix)!=rownames(targets))>0)
  cat("Verifique que las filas del objeto targets coinciden con las columnas de la matriz de datos")


## ----getRowsFromGroup-----------------------------------------------------
getRowsFromGroup <- function(unGrupo, numRows){
  G <-which(targets$group==unGrupo)
  s <- sample(G, numRows)
}


## ----randomSampling-------------------------------------------------------
set.seed(12345678)
S1 <- getRowsFromGroup("COVID", 10)
S2 <- getRowsFromGroup("SANO", 10)
selectedSamples <- c(S1,S2)
# show(selectedSamples)


## ----subconjuntObjetos----------------------------------------------------
selectedCounts <- countsMatrix[,selectedSamples]
selectedTargets <-targets [selectedSamples,] 
dim(selectedCounts)
dim(selectedTargets)
sum(colnames(selectedCounts)!=rownames(selectedTargets))


## ----getCPM---------------------------------------------------------------
library(edgeR)
selectedCounts[1:5,1:6]
counts.CPM <- cpm(selectedCounts)
counts.CPM[1:5,1:6]


## ----subsetThreshold------------------------------------------------------
thresh <- counts.CPM > 0
keep <- (rowSums(thresh[,1:10]) >= 3) &
        (rowSums(thresh[,11:20]) >= 3)
counts.keep <- counts.CPM[keep,]
dim(counts.CPM)
dim(counts.keep)


## ----comparaMatrices------------------------------------------------------
head(counts.CPM)
head(counts.keep)


## ----makeDGEObj0----------------------------------------------------------
dgeObj <- DGEList(counts = counts.keep, 
                  lib.size = colSums(counts.keep),
                  norm.factors = rep(1,ncol(counts.keep)), 
                  samples = selectedTargets,
                  group = selectedTargets$group, 
                  genes = rownames(counts.keep), 
                  remove.zeros = FALSE)
dgeObj


## ----makeDGEObj-----------------------------------------------------------
dim(dgeObj)
dgeObjShort<-dgeObj[,c(1:5, 11:15)]
# Library size information is stored in the samples slot
dgeObjShort$samples
colnames(dgeObjShort$counts)


## ----calcNormFactors------------------------------------------------------
library(edgeR)
dgeObj_norm <- calcNormFactors(dgeObj)


## -------------------------------------------------------------------------
dgeObj$counts[1:3, 1:5]
dgeObj_norm$counts[1:3, 1:5]
dgeObj$samples$norm.factors
dgeObj_norm$samples$norm.factors


## ----log2count_norm-------------------------------------------------------
log2count_norm <- cpm(dgeObj_norm, log=TRUE)


## ----distriCounts1--------------------------------------------------------
par(mfrow=c(2,1))
rawCounts <- dgeObj_norm$counts
boxplot(rawCounts, ylab="CPM",las=2, xlab="", col = dgeObj$samples$cols, cex.axis=0.7, main="Distribución de contajes")
boxplot(log2count_norm, ylab="Log2-CPM",las=2, xlab="", col=dgeObj$samples$cols, cex.axis=0.7, main="Distribución de log(contajes)")
abline(h=median(log2count_norm), col="blue")
par(mfrow=c(1,1))


## -------------------------------------------------------------------------
sampleDists <- dist(t(log2count_norm))
round(sampleDists,1)


## -------------------------------------------------------------------------
library(factoextra)
fviz_dist(sampleDists)


## -------------------------------------------------------------------------
hc <-hclust(sampleDists)
plot(hc,labels = colnames(log2count_norm),main = "Agrpamiento jerárquico de las muestras", cex=0.8)


## -------------------------------------------------------------------------
normFactors <- dgeObj_norm$samples$norm.factors
names(normFactors)<- sampleNames <- rownames(dgeObj_norm$samples)
plot(normFactors, main= "Factores de normalización")
text(normFactors, sampleNames, pos=2, cex=0.7)


## -------------------------------------------------------------------------
#sampleinfo$Status <- factor (sampleinfo$group)
col.status <- dgeObj_norm$samples$cols
plotMDS(log2count_norm,col=col.status, main="Status", cex=0.7)


## ----matrizDisenyo--------------------------------------------------------
group = as.factor(dgeObj_norm$samples$group)
design = model.matrix(~ 0 + group)
colnames(design) = gsub("group", "", colnames(design))
row.names(design) = sampleNames
design


## ----matrizContrastes-----------------------------------------------------
cont.matrix = makeContrasts(CONTROLvsCOVID = COVID - SANO,
levels=colnames(design))
cont.matrix


## ----voom-----------------------------------------------------------------
voomObj <- voom(dgeObj_norm, design)
voomObj


## ----ajusteLM-------------------------------------------------------------
fit <- lmFit(voomObj)
fit.cont <- contrasts.fit(fit, cont.matrix)
fit.cont <- eBayes(fit.cont)


## ----topTable-------------------------------------------------------------
toptab <- topTable(fit.cont,coef=1,sort.by="p", number=nrow(fit.cont))
head(toptab)


## ----volcano--------------------------------------------------------------
volcanoplot(fit.cont,coef=1,highlight=100, main="COVID vs SANO")


## ----deg1VOOM-------------------------------------------------------------
topGenesBas <- rownames(subset(toptab, (abs(logFC)> 2) & (adj.P.Val < 0.01)))
length(topGenesBas)


## ----mapaDeColores--------------------------------------------------------
library(pheatmap)
mat  <- log2count_norm[topGenesBas, ]
mat  <- mat - rowMeans(mat)
pheatmap(mat)


## -------------------------------------------------------------------------
y = estimateDisp(dgeObj_norm, design, robust=TRUE)
plotBCV(y)


## -------------------------------------------------------------------------
fit <- glmQLFit(y, design, robust = TRUE)


## -------------------------------------------------------------------------
res <- glmQLFTest(fit, contrast = cont.matrix)
head(res)


## -------------------------------------------------------------------------
topTags_edge <- topTags(res, n=dim(log2count_norm)[1]) # todos los genes
head(topTags_edge)


## -------------------------------------------------------------------------
topGenes_edge <- rownames(subset(topTags_edge$table, (abs(logFC)> 2) & (FDR < 0.01)))
length(topGenes_edge)


## ----comparaVoomEdgeR-----------------------------------------------------
library(ggvenn)
x = list(LimmaVoom = topGenesBas, edgeR = topGenes_edge)
ggvenn(x, fill_color = c("#0073C2FF", "#EFC000FF"), stroke_size = 0.5, set_name_size = 3)


## -------------------------------------------------------------------------
topGenes <- union(topGenesBas, topGenes_edge)
length(topGenes)
universe <- rownames(toptab)
length(universe)


## ----anotaTop-------------------------------------------------------------
library(org.Hs.eg.db)
AnnotationDbi::keytypes(org.Hs.eg.db)
topAnots = AnnotationDbi::select(org.Hs.eg.db, topGenes, c("SYMBOL", "ENTREZID", "GENENAME"),
keytype = "ENSEMBL")
head(topAnots)
dim(topAnots)


## -------------------------------------------------------------------------
univAnots = AnnotationDbi::select(org.Hs.eg.db, universe, c("SYMBOL", "ENTREZID", "GENENAME"), keytype = "ENSEMBL")
head(univAnots)
dim(univAnots)


## ----enrichment-----------------------------------------------------------
library(clusterProfiler)
library(org.Hs.eg.db)
ego = enrichGO(gene = topGenes, 
               universe=universe,
               keyType = "ENSEMBL", 
               OrgDb = org.Hs.eg.db,
               ont="BP",
               pAdjustMethod = "BH",
               pvalueCutoff = 0.05,
               qvalueCutoff = 0.05,
               readable = TRUE)


## ----saveEnrichedTerms----------------------------------------------------
head(ego[,-c(2,8)], n=5)
head(ego[,2:3], n=5)
head(ego[,c(2,8)], n=5)
write.table(ego, file="results/EnrichmentResults.csv", dec=".", sep=";")


## ----viewEnrichment1------------------------------------------------------
dotplot(ego, showCategory=7)


## ----viewEnrichment2------------------------------------------------------
library(ggplot2)
ego2 = simplify(ego)
cnetplot(ego2, showCategory = 3, cex_category =0.3, 
         cex_label_category =0.7, cex_gene=0.2, cex_label_gene=0.4,
         circular=TRUE, colorEdge=TRUE)


## ----viewEnrichment3------------------------------------------------------
library(enrichplot)
goplot(ego2, showCategory=10, cex=0.1)


## ----viewEnrichment5------------------------------------------------------
heatplot(ego2)


## ----viewEnrichment6------------------------------------------------------
term_similarity_matrix = pairwise_termsim(ego)
emapplot(term_similarity_matrix, showCategory = 15,
         group_category=TRUE, group_legend=TRUE)


## -------------------------------------------------------------------------
pdf(file="results/enrichmentPlots.pdf")
dotplot(ego, showCategory=7)
cnetplot(ego2, showCategory = 3, cex_category =0.3, 
         cex_label_category =0.7, cex_gene=0.2, cex_label_gene=0.4,
         circular=TRUE, colorEdge=TRUE)
goplot(ego2, showCategory=10, cex=0.1)
heatplot(ego2)
emapplot(term_similarity_matrix, showCategory = 15,
         group_category=TRUE, group_legend=TRUE)
dev.off()


## ----insertaCodigo,  echo=TRUE, eval=FALSE, highlight=TRUE----------------



```

